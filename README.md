# ✅ Task 5: Decision Trees and Random Forests

## 📌 Done by: Krishna

---

## ✅ Objective:
In this task, I (Krishna) worked on Decision Tree and Random Forest models for regression using the Housing.csv dataset.

---

## ✅ What I did step by step:

1. 📥 First I uploaded the dataset (Housing.csv) in Google Colab.

2. 🧹 I checked for missing values and did One-Hot Encoding for categorical columns.

3. 🧪 I split the data into X (features) and y (target - price).

4. 📊 I did Train-Test Split (80% train, 20% test).

5. 🌳 I trained a **Decision Tree Regressor** and checked its Mean Squared Error (MSE).

6. 👁 I visualized the Decision Tree with limited depth (max_depth=3 for graph, max_depth=5 for reducing overfitting).

7. 🌲 After that, I trained a **Random Forest Regressor** and compared its performance with Decision Tree.

8. ⭐ I plotted **Feature Importance** from Random Forest.

9. 🔁 Finally, I did **5-Fold Cross Validation** for Random Forest to check model stability.

---

## ✅ Libraries I Used:
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn

---

## ✅ Results I observed:

- ✅ Random Forest gave better performance (lower MSE) than Decision Tree.
- ✅ Limiting tree depth helped reduce overfitting.
- ✅ Feature Importance graph showed which features affect price prediction.
- ✅ Cross-validation showed stable performance.

---

## ✅ Folder Structure (for GitHub):


